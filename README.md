# Benchmarking LLM Inference on Kubernetes: LLaMa-3.1-8b and Granite-3.1-8b on Triton, TensorRT-LLM and vLLM

Benchmarking Large Language Model Inference on Kubernetes: Comparing Triton, TensorRT-LLM, and vLLM on Llama 3.1 and Granite 3.1

Test configurtions:

1. llama-3.1-8b + Triton + Linux
1. llama-3.1-8b + TensorRT-LLM + Linux
1. llama-3.1-8b + vLLM + Linux
1. granite-3.1-8b + Triton + Kubernetes
1. granite-3.1-8b + TensorRT-LLM + Kuberentes
1. granite-3.1-8b + vLLM + Kubernetes